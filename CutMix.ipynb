{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CutMix.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dToebnl168KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# Title= CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features \n",
        "# Author= Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon,\n",
        "# Booktitle = International Conference on Computer Vision (ICCV)\n",
        "# Year=2019\n",
        "# Availability: https://github.com/clovaai/CutMix-PyTorch\n",
        "################################################################################\n",
        "\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDz3tc4o0vee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Original code: https://github.com/dyhan0920/PyramidNet-PyTorch/blob/master/PyramidNet.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    outchannel_ratio = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)        \n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(out)        \n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn3(out)\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "            featuremap_size = shortcut.size()[2:4]\n",
        "        else:\n",
        "            shortcut = x\n",
        "            featuremap_size = out.size()[2:4]\n",
        "\n",
        "        batch_size = out.size()[0]\n",
        "        residual_channel = out.size()[1]\n",
        "        shortcut_channel = shortcut.size()[1]\n",
        "\n",
        "        if residual_channel != shortcut_channel:\n",
        "            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n",
        "            out += torch.cat((shortcut, padding), 1)\n",
        "        else:\n",
        "            out += shortcut \n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    outchannel_ratio = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, reduction=16):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, (planes), kernel_size=3, stride=stride, padding=1, bias=False, groups=1)\n",
        "        self.bn3 = nn.BatchNorm2d((planes))\n",
        "        self.conv3 = nn.Conv2d((planes), planes * Bottleneck.outchannel_ratio, kernel_size=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm2d(planes * Bottleneck.outchannel_ratio)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.conv1(out)\n",
        "        \n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        " \n",
        "        out = self.bn3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        out = self.bn4(out)\n",
        "        if self.downsample is not None:\n",
        "            shortcut = self.downsample(x)\n",
        "            featuremap_size = shortcut.size()[2:4]\n",
        "        else:\n",
        "            shortcut = x\n",
        "            featuremap_size = out.size()[2:4]\n",
        "\n",
        "        batch_size = out.size()[0]\n",
        "        residual_channel = out.size()[1]\n",
        "        shortcut_channel = shortcut.size()[1]\n",
        "\n",
        "        if residual_channel != shortcut_channel:\n",
        "            padding = torch.autograd.Variable(torch.cuda.FloatTensor(batch_size, residual_channel - shortcut_channel, featuremap_size[0], featuremap_size[1]).fill_(0)) \n",
        "            out += torch.cat((shortcut, padding), 1)\n",
        "        else:\n",
        "            out += shortcut \n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class PyramidNet(nn.Module):\n",
        "        \n",
        "    def __init__(self, dataset, depth, alpha, num_classes, bottleneck=False):\n",
        "        super(PyramidNet, self).__init__()   \t\n",
        "        self.dataset = dataset\n",
        "        if self.dataset.startswith('cifar'):\n",
        "            self.inplanes = 16\n",
        "            if bottleneck == True:\n",
        "                n = int((depth - 2) / 9)\n",
        "                block = Bottleneck\n",
        "            else:\n",
        "                n = int((depth - 2) / 6)\n",
        "                block = BasicBlock\n",
        "\n",
        "            self.addrate = alpha / (3*n*1.0)\n",
        "\n",
        "            self.input_featuremap_dim = self.inplanes\n",
        "            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
        "\n",
        "            self.featuremap_dim = self.input_featuremap_dim \n",
        "            self.layer1 = self.pyramidal_make_layer(block, n)\n",
        "            self.layer2 = self.pyramidal_make_layer(block, n, stride=2)\n",
        "            self.layer3 = self.pyramidal_make_layer(block, n, stride=2)\n",
        "\n",
        "            self.final_featuremap_dim = self.input_featuremap_dim\n",
        "            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n",
        "            self.relu_final = nn.ReLU(inplace=True)\n",
        "            self.avgpool = nn.AvgPool2d(8)\n",
        "            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
        "\n",
        "        elif dataset == 'imagenet':\n",
        "            blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n",
        "            layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n",
        "\n",
        "            if layers.get(depth) is None:\n",
        "                if bottleneck == True:\n",
        "                    blocks[depth] = Bottleneck\n",
        "                    temp_cfg = int((depth-2)/12)\n",
        "                else:\n",
        "                    blocks[depth] = BasicBlock\n",
        "                    temp_cfg = int((depth-2)/8)\n",
        "\n",
        "                layers[depth]= [temp_cfg, temp_cfg, temp_cfg, temp_cfg]\n",
        "                print('=> the layer configuration for each stage is set to', layers[depth])\n",
        "\n",
        "            self.inplanes = 64            \n",
        "            self.addrate = alpha / (sum(layers[depth])*1.0)\n",
        "\n",
        "            self.input_featuremap_dim = self.inplanes\n",
        "            self.conv1 = nn.Conv2d(3, self.input_featuremap_dim, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(self.input_featuremap_dim)\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "            self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "            self.featuremap_dim = self.input_featuremap_dim \n",
        "            self.layer1 = self.pyramidal_make_layer(blocks[depth], layers[depth][0])\n",
        "            self.layer2 = self.pyramidal_make_layer(blocks[depth], layers[depth][1], stride=2)\n",
        "            self.layer3 = self.pyramidal_make_layer(blocks[depth], layers[depth][2], stride=2)\n",
        "            self.layer4 = self.pyramidal_make_layer(blocks[depth], layers[depth][3], stride=2)\n",
        "\n",
        "            self.final_featuremap_dim = self.input_featuremap_dim\n",
        "            self.bn_final= nn.BatchNorm2d(self.final_featuremap_dim)\n",
        "            self.relu_final = nn.ReLU(inplace=True)\n",
        "            self.avgpool = nn.AvgPool2d(7) \n",
        "            self.fc = nn.Linear(self.final_featuremap_dim, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def pyramidal_make_layer(self, block, block_depth, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1: # or self.inplanes != int(round(featuremap_dim_1st)) * block.outchannel_ratio:\n",
        "            downsample = nn.AvgPool2d((2,2), stride = (2, 2), ceil_mode=True)\n",
        "\n",
        "        layers = []\n",
        "        self.featuremap_dim = self.featuremap_dim + self.addrate\n",
        "        layers.append(block(self.input_featuremap_dim, int(round(self.featuremap_dim)), stride, downsample))\n",
        "        for i in range(1, block_depth):\n",
        "            temp_featuremap_dim = self.featuremap_dim + self.addrate\n",
        "            layers.append(block(int(round(self.featuremap_dim)) * block.outchannel_ratio, int(round(temp_featuremap_dim)), 1))\n",
        "            self.featuremap_dim  = temp_featuremap_dim\n",
        "        self.input_featuremap_dim = int(round(self.featuremap_dim)) * block.outchannel_ratio\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.dataset == 'cifar10' or self.dataset == 'cifar100':\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            \n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = self.layer3(x)\n",
        "\n",
        "            x = self.bn_final(x)\n",
        "            x = self.relu_final(x)\n",
        "            x = self.avgpool(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "\n",
        "        elif self.dataset == 'imagenet':\n",
        "            x = self.conv1(x)\n",
        "            x = self.bn1(x)\n",
        "            x = self.relu(x)\n",
        "            x = self.maxpool(x)\n",
        "\n",
        "            x = self.layer1(x)\n",
        "            x = self.layer2(x)\n",
        "            x = self.layer3(x)\n",
        "            x = self.layer4(x)\n",
        "\n",
        "            x = self.bn_final(x)\n",
        "            x = self.relu_final(x)\n",
        "            x = self.avgpool(x)\n",
        "            x = x.view(x.size(0), -1)\n",
        "            x = self.fc(x)\n",
        "    \n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fk8RVjo1PQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size=32\n",
        "dataset =\"cifar10\"\n",
        "depth=200\n",
        "net_type=\"pyramidnet\"\n",
        "alpha=240\n",
        "lr=0.25\n",
        "expname=\"PyraNet200\"\n",
        "epochs=10\n",
        "beta=1.0\n",
        "cutmix_prob=0.5\n",
        "print_freq=10\n",
        "verbose=True\n",
        "workers=4\n",
        "momentum=0.9\n",
        "weight_decay=1e-4\n",
        "best_err1 = 100\n",
        "best_err5 = 100\n",
        "\n",
        "\n",
        "def main():\n",
        "    global best_err1\n",
        "    # Normalize a tensor image with mean and standard deviation.\n",
        "    # Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform will normalize each channel of the input torch\n",
        "    normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                             std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "    # Transforms are common image transformations. They can be chanined together using Compose.\n",
        "    # Compose composes several transformations together\n",
        "\n",
        "\n",
        "    # RandomCrop - Crop the given PIL(Pillow) image at a random location. Size is the desired output size of the crop. Optional padding on each border of the image\n",
        "    # RandomHorizontalFlip - Horizontally flip the given PIL image randomly with a given probability\n",
        "    # ToTensor - Convert a PIL image or numpy.ndarray(HxWxC) to to tensor of shape (CXHXW)\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                normalize\n",
        "            ])\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10('../data', train=True, download=True, transform=transform_train),\n",
        "                    batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "                    datasets.CIFAR10('../data', train=False, transform=transform_test),\n",
        "                    batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n",
        "    numberofclass = 10\n",
        "\n",
        "    # Create a network\n",
        "    model = PyramidNet(dataset, depth, alpha, numberofclass, bottleneck=True)\n",
        "\n",
        "    # Make your model run parallel\n",
        "    model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "    # CrossEntropyLoss - combines LogSoftMax and negative log likelihood loss in one single class.\n",
        "    # It is useful when training a classification problem with C classes.\n",
        "    # The input is expected to contain raw, unnormalized scores for each class.\n",
        "    criterion = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "\n",
        "    # Implements a Stochastic Gradient Descent to optimize the kernel hyperparameters and the noise level.\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
        "\n",
        "    # Cudnn will look for the optimal set of algorithms for that particular configuration. This leads to faster runtime.\n",
        "    # The flag allows you to enable the buitin cudnn auto-tuner to find the best algorithm to use for your hardware.\n",
        "    cudnn.benchmark = True\n",
        "\n",
        "    ## args.epoch = 300\n",
        "    for epoch in range(0, epochs):\n",
        "\n",
        "        adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "        # train for one epoch\n",
        "        train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
        "\n",
        "        # evaluate on validation set\n",
        "        err1, err5, val_loss = validate(val_loader, model, criterion, epoch)\n",
        "\n",
        "        # remember best prec@1 and save checkpoint\n",
        "        is_best = err1 <= best_err1\n",
        "        best_err1 = min(err1, best_err1)\n",
        "        if is_best:\n",
        "            best_err5 = err5\n",
        "\n",
        "        print('Current best accuracy (top-1 and 5 error):', best_err1, best_err5)\n",
        "        save_checkpoint({\n",
        "            'epoch': epoch,\n",
        "            'arch': net_type,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'best_err1': best_err1,\n",
        "            'best_err5': best_err5,\n",
        "            'optimizer': optimizer.state_dict(),}, is_best)\n",
        "\n",
        "    print('Best accuracy (top-1 and 5 error):', best_err1, best_err5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    current_LR = get_learning_rate(optimizer)[0]\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        r = np.random.rand(1)\n",
        "        if beta > 0 and r < cutmix_prob:\n",
        "            # generate mixed sample\n",
        "            # Draw samples from a Beta distribution, beta =1.0\n",
        "            # randperm - returns a random permutation of integers from 0 to n-1\n",
        "            lam = np.random.beta(beta, beta)\n",
        "            rand_index = torch.randperm(input.size()[0]).cuda()\n",
        "            target_a = target\n",
        "            target_b = target[rand_index]\n",
        "\n",
        "\n",
        "\n",
        "            bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n",
        "            input[:, :, bbx1:bbx2, bby1:bby2] = input[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
        "            # adjust lambda to exactly match pixel ratio\n",
        "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n",
        "            # compute output\n",
        "            input_var = torch.autograd.Variable(input, requires_grad=True)\n",
        "            target_a_var = torch.autograd.Variable(target_a)\n",
        "            target_b_var = torch.autograd.Variable(target_b)\n",
        "            output = model(input_var)\n",
        "            loss = criterion(output, target_a_var) * lam + criterion(output, target_b_var) * (1. - lam)\n",
        "        else:\n",
        "            # compute output\n",
        "            input_var = torch.autograd.Variable(input, requires_grad=True)\n",
        "            target_var = torch.autograd.Variable(target)\n",
        "            output = model(input_var)\n",
        "            loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        err1, err5 = accuracy(output.data, target, topk=(1, 5))\n",
        "\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(err1.item(), input.size(0))\n",
        "        top5.update(err5.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0 and verbose == True:\n",
        "            print('Epoch: [{0}/{1}][{2}/{3}]\\t'\n",
        "                  'LR: {LR:.6f}\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Top 1-err {top1.val:.4f} ({top1.avg:.4f})\\t'\n",
        "                  'Top 5-err {top5.val:.4f} ({top5.avg:.4f})'.format(\n",
        "                epoch, epochs, i, len(train_loader), LR=current_LR, batch_time=batch_time,\n",
        "                data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
        "\n",
        "    print('* Epoch: [{0}/{1}]\\t Top 1-err {top1.avg:.3f}  Top 5-err {top5.avg:.3f}\\t Train Loss {loss.avg:.3f}'.format(\n",
        "        epoch, epochs, top1=top1, top5=top5, loss=losses))\n",
        "\n",
        "    return losses.avg\n",
        "\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        target = target.cuda()\n",
        "\n",
        "        input_var = torch.autograd.Variable(input)\n",
        "        target_var = torch.autograd.Variable(target)\n",
        "        output = model(input_var)\n",
        "        loss = criterion(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        err1, err5 = accuracy(output.data, target, topk=(1, 5))\n",
        "\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "\n",
        "        top1.update(err1.item(), input.size(0))\n",
        "        top5.update(err5.item(), input.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0 and verbose == True:\n",
        "            print('Test (on val set): [{0}/{1}][{2}/{3}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Top 1-err {top1.val:.4f} ({top1.avg:.4f})\\t'\n",
        "                  'Top 5-err {top5.val:.4f} ({top5.avg:.4f})'.format(\n",
        "                   epoch, epochs, i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                   top1=top1, top5=top5))\n",
        "\n",
        "    print('* Epoch: [{0}/{1}]\\t Top 1-err {top1.avg:.3f}  Top 5-err {top5.avg:.3f}\\t Test Loss {loss.avg:.3f}'.format(\n",
        "        epoch, epochs, top1=top1, top5=top5, loss=losses))\n",
        "    return top1.avg, top5.avg, losses.avg\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    directory = \"runs/%s/\" % (expname)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    filename = directory + filename\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'runs/%s/' % (expname) + 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    global lr\n",
        "    if dataset.startswith('cifar'):\n",
        "        lr = lr * (0.1 ** (epoch // (epochs * 0.5))) * (0.1 ** (epoch // (epochs * 0.75)))\n",
        "    elif dataset == ('imagenet'):\n",
        "        if epochs == 300:\n",
        "            lr = lr * (0.1 ** (epoch // 75))\n",
        "        else:\n",
        "            lr = lr * (0.1 ** (epoch // 30))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "\n",
        "def get_learning_rate(optimizer):\n",
        "    lr = []\n",
        "    for param_group in optimizer.param_groups:\n",
        "        lr += [param_group['lr']]\n",
        "    return lr\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "        wrong_k = batch_size - correct_k\n",
        "        res.append(wrong_k.mul_(100.0 / batch_size))\n",
        "\n",
        "    return res\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3KcYyK18F_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}